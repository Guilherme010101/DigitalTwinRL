{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8079cecc",
   "metadata": {},
   "source": [
    "# 1 - Importa bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc6fa3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from torch.nn import Tanh, ELU, ReLU, Sigmoid, Softmax\n",
    "import websocket\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import random\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import gym\n",
    "import stable_baselines3\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Tuple, MultiDiscrete\n",
    "from stable_baselines3 import PPO, DQN, A2C, SAC, TD3, DDPG\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, CallbackList, ProgressBarCallback, TensorboardCallback, EvalCallback\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from sb3_contrib import RecurrentPPO, TQC, QRDQN, MaskablePPO, TRPO, ARS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bad143",
   "metadata": {},
   "source": [
    "# 2 - Cria funções de encoding/decoding em json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "217f60d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):            \n",
    "            return obj.tolist()\n",
    "        \n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "identifier =''\n",
    "actions =[]\n",
    "message = ''\n",
    "\n",
    "\n",
    "def encode_json(identifier, actions):\n",
    "    data = {}\n",
    "    data['identifier'] = identifier\n",
    "    data['actions'] = actions\n",
    "    json_data = json.dumps(data, cls=NumpyEncoder)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db6a0a5",
   "metadata": {},
   "source": [
    "# 3 - Define função de criação do agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc4b64b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrillEnv(Env):\n",
    "    \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def _reset(self):\n",
    "        \n",
    "        self.reward = 0\n",
    "        self.action_name = ''\n",
    "        self.Can = False\n",
    "        self.SensorHandling = False\n",
    "        self.SensorRobot = False\n",
    "        self.ConveyorPosition = 0\n",
    "        actions = []\n",
    "        self.buffer_size = tamanho_buffer        \n",
    "        self.state_buffer = np.zeros((self.buffer_size * 4))\n",
    "        \n",
    "    def _obs(self):\n",
    "        obs= self.state_buffer\n",
    "                     \n",
    "        return obs\n",
    "        \n",
    "\n",
    "    def setprint(self, print):\n",
    "        self.print = print \n",
    "    def setprint2(self, print):\n",
    "        self.print2 = print\n",
    "    \n",
    "    def __init__(self):     \n",
    "        super(DrillEnv, self).__init__()\n",
    "        self.reset()\n",
    "\n",
    "        self.print = False\n",
    "        self.print2 = False\n",
    "\n",
    "        #Actions we can take, Forward_off and Backward_off, Forward_on,  Backward_on\n",
    "        #self.action_space = Box(low=0, high=630, shape=(5,),dtype=np.int8)\n",
    "        #elf.action_space = MultiDiscrete([2,630,200])\n",
    "        self.action_space = Discrete(3)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #sensors taken ConveyorFinish, GripperClose, GantryYposition, GantryYatDestination, GantryZPosition,GantryZatDestination, GantryYdriving, GantryZdriving \n",
    "        self.observation_space = Box(low=0, high=1, shape=(1,self.buffer_size * 4), dtype=np.float32)\n",
    "\n",
    "\n",
    "    def buffer(self, Can,SensorHandling, SensorRobot, ConveyorPosition):\n",
    "        #for x in range(self.buffer_size-1):\n",
    "            #self.state_buffer[x] = self.state_buffer[x+1]   \n",
    "       \n",
    "        self.state_buffer = np.roll(self.state_buffer,4)\n",
    "         \n",
    "        self.state_buffer[0] = Can \n",
    "        self.state_buffer[1] = SensorHandling \n",
    "        self.state_buffer[2] = SensorRobot\n",
    "        self.state_buffer[3] = ConveyorPosition \n",
    "\n",
    "        \n",
    "        #self.state_buffer[self.buffer_size-1] = [ConveyorFinish, Picked, GantryYposition,\n",
    "                   #GantryZPosition, GripperClose, ChangeCycle]\n",
    "        \n",
    "    def step(self, action):\n",
    "        actions = action\n",
    "        \n",
    "        #actions = np.array(action) * 100\n",
    "        #actions = np.argmax(actions)\n",
    "        \n",
    "        mensagem = encode_json('BoxConveyor_manual',  [actions])\n",
    "        \n",
    "        ws.send(mensagem)\n",
    "        data =''\n",
    "        station_identifier = ''\n",
    "        while  station_identifier != 'BoxConveyor':\n",
    "            try:\n",
    "                data = json.loads(ws.recv())                \n",
    "                station_identifier = (data['identifier'])\n",
    "            except:\n",
    "                return\n",
    "        \n",
    "        self.reward = int(data['reward'])\n",
    "         \n",
    "        if bool(data['done']) == False:\n",
    "            done = False\n",
    "        else:\n",
    "            done = True\n",
    "               \n",
    "        self.Can = bool(data['states'][0])\n",
    "        self.SensorHandling = bool(data['states'][1])\n",
    "        self.SensorRobot = bool(data['states'][2])\n",
    "        self.ConveyorPosition = float(data['states'][3])\n",
    "\n",
    "        #self.buffer(self.Can, self.ConveyorPosition)        \n",
    "        self.buffer(self.Can, self.SensorHandling, self.SensorRobot,self.ConveyorPosition) \n",
    "\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        obs=self._obs()\n",
    "        if self.print:  \n",
    "            print('recompensa: ',self.reward,'|  acao --> ', actions,'|  done: ', done, '| Estado: ',self.state_buffer[0:4])\n",
    "            #print(self.state_buffer)\n",
    "   \n",
    "        #print (obs)\n",
    "        # Return step information\n",
    "        return obs, self.reward, done, info\n",
    "    \n",
    "    def render(self , mode):\n",
    "        #print(\"teste\")\n",
    "        pass\n",
    "    def reset(self):\n",
    "        \n",
    "        self._reset()\n",
    "        return self._obs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d2da0",
   "metadata": {},
   "source": [
    "# Ponto de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a847ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "ActorCriticPolicy(\n",
      "  (features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (shared_net): Sequential()\n",
      "    (policy_net): Sequential(\n",
      "      (0): Linear(in_features=12, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): Tanh()\n",
      "    )\n",
      "    (value_net): Sequential(\n",
      "      (0): Linear(in_features=12, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (action_net): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Logging to Dissertacao\\Training_BoxConveyor\\Logs\\PPO_B03\\PPO_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                       | 4084/1000000 [00:38<1:25:28, 194.18it/s]C:\\Users\\Tiago\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4096, episode_reward=723.33 +/- 611.73\n",
      "Episode length: 64.33 +/- 42.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 64.3        |\n",
      "|    mean_reward          | 723         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008596173 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.00299    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.75e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    value_loss           | 3.42e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                       | 8174/1000000 [01:15<1:57:29, 140.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=8192, episode_reward=159.33 +/- 163.43\n",
      "Episode length: 48.33 +/- 21.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 48.3        |\n",
      "|    mean_reward          | 159         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012631389 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.00412     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.01e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 1.15e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                      | 12274/1000000 [01:52<2:00:10, 136.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=12288, episode_reward=95.00 +/- 134.35\n",
      "Episode length: 31.00 +/- 24.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31          |\n",
      "|    mean_reward          | 95          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005225811 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.937      |\n",
      "|    explained_variance   | 0.000245    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.62e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    value_loss           | 1.39e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▏                                                                     | 16380/1000000 [02:28<1:18:51, 207.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=16384, episode_reward=491.33 +/- 500.95\n",
      "Episode length: 28.67 +/- 28.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 28.7         |\n",
      "|    mean_reward          | 491          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039754407 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.811       |\n",
      "|    explained_variance   | 1.31e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02e+04     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    value_loss           | 2.21e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                     | 20466/1000000 [03:04<2:03:14, 132.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=20480, episode_reward=391.67 +/- 367.31\n",
      "Episode length: 30.00 +/- 19.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30           |\n",
      "|    mean_reward          | 392          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031046076 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.729       |\n",
      "|    explained_variance   | -5.33e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.39e+03     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 2.35e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                     | 24575/1000000 [03:39<1:25:39, 189.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=24576, episode_reward=653.67 +/- 489.00\n",
      "Episode length: 47.67 +/- 23.67\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 47.7         |\n",
      "|    mean_reward          | 654          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047253524 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.588       |\n",
      "|    explained_variance   | -6.21e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.6e+03      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | 0.00245      |\n",
      "|    value_loss           | 1.77e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██                                                                     | 28664/1000000 [04:13<1:26:22, 187.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=28672, episode_reward=393.67 +/- 278.36\n",
      "Episode length: 44.00 +/- 27.07\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 44           |\n",
      "|    mean_reward          | 394          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031631642 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | -7.03e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.03e+03     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    value_loss           | 1.41e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▎                                                                    | 32768/1000000 [04:48<1:43:13, 156.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=32768, episode_reward=493.67 +/- 504.15\n",
      "Episode length: 28.00 +/- 14.85\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 28            |\n",
      "|    mean_reward          | 494           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.7936315e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.618        |\n",
      "|    explained_variance   | -1.31e-06     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.1e+04       |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.000447     |\n",
      "|    value_loss           | 5.59e+04      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▌                                                                    | 36860/1000000 [05:23<1:49:08, 147.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=36864, episode_reward=195.67 +/- 138.36\n",
      "Episode length: 34.33 +/- 8.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 34.3         |\n",
      "|    mean_reward          | 196          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022562996 |\n",
      "|    clip_fraction        | 0.00962      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.623       |\n",
      "|    explained_variance   | -1.91e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+04      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    value_loss           | 3.2e+04      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▉                                                                    | 40956/1000000 [05:58<1:56:38, 137.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=40960, episode_reward=558.33 +/- 186.21\n",
      "Episode length: 32.33 +/- 18.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.3        |\n",
      "|    mean_reward          | 558         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023970153 |\n",
      "|    clip_fraction        | 0.0553      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.569      |\n",
      "|    explained_variance   | -2.03e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+04    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    value_loss           | 1.99e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▏                                                                   | 45044/1000000 [06:33<1:55:42, 137.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=45056, episode_reward=789.00 +/- 607.84\n",
      "Episode length: 35.00 +/- 18.06\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 35           |\n",
      "|    mean_reward          | 789          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026524717 |\n",
      "|    clip_fraction        | 0.222        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.666       |\n",
      "|    explained_variance   | -1.19e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.48e+04     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | 0.024        |\n",
      "|    value_loss           | 3.26e+04     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▍                                                                   | 49143/1000000 [07:07<1:55:12, 137.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=49152, episode_reward=196.33 +/- 138.83\n",
      "Episode length: 58.67 +/- 41.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 58.7        |\n",
      "|    mean_reward          | 196         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019211091 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | -1.07e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.25e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.0016      |\n",
      "|    value_loss           | 1.78e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                   | 53236/1000000 [07:45<2:09:41, 121.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=53248, episode_reward=525.00 +/- 547.28\n",
      "Episode length: 85.00 +/- 80.65\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 85           |\n",
      "|    mean_reward          | 525          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048164623 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.54e+03     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.000116    |\n",
      "|    value_loss           | 6.37e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████                                                                   | 57329/1000000 [08:22<1:14:55, 209.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=57344, episode_reward=854.33 +/- 604.11\n",
      "Episode length: 123.33 +/- 68.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 123         |\n",
      "|    mean_reward          | 854         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006759458 |\n",
      "|    clip_fraction        | 0.0632      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.409      |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.7e+03     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    value_loss           | 1.33e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▎                                                                  | 61420/1000000 [08:58<1:41:33, 154.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=61440, episode_reward=722.33 +/- 535.86\n",
      "Episode length: 310.33 +/- 177.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 310         |\n",
      "|    mean_reward          | 722         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033963315 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.483      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.89e+03    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.000712    |\n",
      "|    value_loss           | 1.13e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████▋                                                                  | 65530/1000000 [09:37<1:53:24, 137.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=65536, episode_reward=822.67 +/- 583.14\n",
      "Episode length: 269.33 +/- 204.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 269         |\n",
      "|    mean_reward          | 823         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010502535 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.548      |\n",
      "|    explained_variance   | -3.58e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.000355   |\n",
      "|    value_loss           | 5.28e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████▉                                                                  | 69625/1000000 [10:15<1:53:07, 137.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=69632, episode_reward=163.67 +/- 122.58\n",
      "Episode length: 305.33 +/- 63.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 305         |\n",
      "|    mean_reward          | 164         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008221904 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.89e+03    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    value_loss           | 7.57e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▏                                                                 | 73726/1000000 [10:54<1:39:08, 155.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=73728, episode_reward=523.00 +/- 166.93\n",
      "Episode length: 493.33 +/- 10.84\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 493       |\n",
      "|    mean_reward          | 523       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.031549  |\n",
      "|    clip_fraction        | 0.0579    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.45     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.17e+03  |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | 0.000378  |\n",
      "|    value_loss           | 5.33e+03  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████▌                                                                 | 77824/1000000 [11:35<2:05:11, 122.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=77824, episode_reward=327.00 +/- 282.84\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 327         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002775162 |\n",
      "|    clip_fraction        | 0.0128      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72e+03    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.000673   |\n",
      "|    value_loss           | 2.16e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████▊                                                                 | 81918/1000000 [12:17<1:57:52, 129.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=81920, episode_reward=391.00 +/- 365.35\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 391          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033560304 |\n",
      "|    clip_fraction        | 0.0676       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.323       |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.44e+03     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    value_loss           | 3.75e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████                                                                 | 85997/1000000 [12:57<1:22:49, 183.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=86016, episode_reward=889.33 +/- 630.18\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 889          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053108577 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.243       |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.48e+03     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    value_loss           | 2.75e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▍                                                                | 90102/1000000 [13:37<1:55:34, 131.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=90112, episode_reward=196.67 +/- 139.06\n",
      "Episode length: 381.00 +/- 93.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 381         |\n",
      "|    mean_reward          | 197         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004598971 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41e+03    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    value_loss           | 4.96e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▋                                                                | 94204/1000000 [14:16<1:36:20, 156.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=94208, episode_reward=526.00 +/- 380.62\n",
      "Episode length: 335.00 +/- 234.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 526          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056520114 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.349       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+04     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | 0.000865     |\n",
      "|    value_loss           | 9.88e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████▉                                                                | 98301/1000000 [14:54<1:34:50, 158.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=98304, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 658          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055616777 |\n",
      "|    clip_fraction        | 0.0539       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.312       |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.78e+03     |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.000431    |\n",
      "|    value_loss           | 4.55e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▏                                                              | 102396/1000000 [15:33<1:12:12, 207.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=102400, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031850852 |\n",
      "|    clip_fraction        | 0.045       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.15e+03    |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | 8.47e-05    |\n",
      "|    value_loss           | 7.21e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████▍                                                              | 106491/1000000 [16:09<1:09:44, 213.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=106496, episode_reward=656.67 +/- 523.09\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 657          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039629266 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.323       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.21e+03     |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | 0.000606     |\n",
      "|    value_loss           | 7.2e+03      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████▋                                                              | 110576/1000000 [16:47<1:20:32, 184.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=110592, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 471.67 +/- 41.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 472        |\n",
      "|    mean_reward          | 658        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 110592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01961736 |\n",
      "|    clip_fraction        | 0.0636     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.358     |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.24e+03   |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | 0.000413   |\n",
      "|    value_loss           | 7.2e+03    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████                                                              | 114687/1000000 [17:23<1:11:29, 206.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=114688, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060318555 |\n",
      "|    clip_fraction        | 0.0718       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.338       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.36e+03     |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | 0.00101      |\n",
      "|    value_loss           | 7.21e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████▎                                                             | 118774/1000000 [18:01<1:05:17, 224.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=118784, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 410.33 +/- 128.22\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 410        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 118784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02027943 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.373     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 104        |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | -0.000931  |\n",
      "|    value_loss           | 8.33e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████▌                                                             | 122861/1000000 [18:38<1:08:20, 213.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=122880, episode_reward=526.33 +/- 549.12\n",
      "Episode length: 335.00 +/- 234.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 526          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009457237 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.288       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.84e+03     |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | 0.000846     |\n",
      "|    value_loss           | 8.34e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████▉                                                             | 126976/1000000 [19:14<1:20:45, 180.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=126976, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020903906 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+04    |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | 0.00509     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████▏                                                            | 131058/1000000 [19:52<1:22:34, 175.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=131072, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 263.33 +/- 204.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 263          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038699037 |\n",
      "|    clip_fraction        | 0.0816       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.357       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+04      |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | 0.000648     |\n",
      "|    value_loss           | 1.15e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████▍                                                            | 135163/1000000 [20:26<1:23:30, 172.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=135168, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 335.00 +/- 234.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052882466 |\n",
      "|    clip_fraction        | 0.0899       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.387       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.06e+03     |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | 0.000721     |\n",
      "|    value_loss           | 7.21e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████▋                                                            | 139248/1000000 [21:00<1:13:06, 196.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=139264, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 658          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032830536 |\n",
      "|    clip_fraction        | 0.0721       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.366       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+03     |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | 0.00042      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████                                                            | 143360/1000000 [21:36<1:07:49, 210.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=143360, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030238773 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.343       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.54e+03     |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | 0.00175      |\n",
      "|    value_loss           | 8.35e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████▎                                                           | 147453/1000000 [22:12<1:06:24, 213.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=147456, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 471.67 +/- 41.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 472        |\n",
      "|    mean_reward          | 658        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01766527 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.351     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.25e+03   |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | 0.00255    |\n",
      "|    value_loss           | 8.33e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████▌                                                           | 151547/1000000 [22:50<1:26:28, 163.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=151552, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013788753 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.66e+03    |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | 0.00136     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████▉                                                           | 155634/1000000 [23:29<1:17:48, 180.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=155648, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 191.33 +/- 134.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 191         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008114809 |\n",
      "|    clip_fraction        | 0.0145      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.364      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.17e+03    |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -5.91e-05   |\n",
      "|    value_loss           | 8.31e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████▏                                                          | 159739/1000000 [24:06<1:23:58, 166.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=159744, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 222.67 +/- 207.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 223          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075727045 |\n",
      "|    clip_fraction        | 0.0947       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.421       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+04     |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | 0.00055      |\n",
      "|    value_loss           | 1.15e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████▍                                                          | 163835/1000000 [24:43<1:19:26, 175.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=163840, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 67.00 +/- 52.27\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 67           |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022373004 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02e+04     |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.000142    |\n",
      "|    value_loss           | 2.26e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████▊                                                          | 167926/1000000 [25:18<1:16:38, 180.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=167936, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 147.00 +/- 108.89\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 147          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024871747 |\n",
      "|    clip_fraction        | 0.0905       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.403       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.79e+03     |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | 0.00167      |\n",
      "|    value_loss           | 1.31e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████                                                          | 172017/1000000 [25:52<1:04:29, 213.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=172032, episode_reward=1218.33 +/- 92.87\n",
      "Episode length: 250.67 +/- 141.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 251         |\n",
      "|    mean_reward          | 1.22e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006049175 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.408      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02e+04    |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.000493   |\n",
      "|    value_loss           | 1.31e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████▎                                                         | 176108/1000000 [26:26<1:12:04, 190.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=176128, episode_reward=1284.00 +/- 0.00\n",
      "Episode length: 146.00 +/- 95.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 146          |\n",
      "|    mean_reward          | 1.28e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045187846 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+04     |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.000605    |\n",
      "|    value_loss           | 2.8e+04      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████▌                                                         | 180209/1000000 [26:59<1:03:14, 216.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=180224, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 169.67 +/- 192.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 170         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028494125 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.49       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+04    |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | 0.0019      |\n",
      "|    value_loss           | 1.2e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████▉                                                         | 184309/1000000 [27:33<1:48:16, 125.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=184320, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.33 +/- 235.70\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 334          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048816237 |\n",
      "|    clip_fraction        | 0.0904       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.356       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.52e+03     |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | 0.00102      |\n",
      "|    value_loss           | 1.46e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████▏                                                        | 188414/1000000 [28:08<1:17:47, 173.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=188416, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 428.67 +/- 102.29\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 429          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037913073 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.293       |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.45e+03     |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | 9.9e-05      |\n",
      "|    value_loss           | 8.4e+03      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████▍                                                        | 192510/1000000 [28:44<1:06:38, 201.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=192512, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 192512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026229697 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.313       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.05e+03     |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | 0.000241     |\n",
      "|    value_loss           | 8.36e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████▊                                                        | 196602/1000000 [29:22<1:23:56, 159.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=196608, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 246.00 +/- 178.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 246         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006629374 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.39       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.47e+03    |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | 0.000652    |\n",
      "|    value_loss           | 8.34e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████                                                        | 200688/1000000 [29:56<1:06:16, 201.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=200704, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 226.00 +/- 207.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 226         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017479107 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.411      |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.38e+03    |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | 0.000155    |\n",
      "|    value_loss           | 9.92e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▎                                                       | 204778/1000000 [30:30<1:08:49, 192.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=204800, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 195.67 +/- 122.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 196         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005938445 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.383      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.19e+03    |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.000486   |\n",
      "|    value_loss           | 1.47e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████▌                                                       | 208892/1000000 [31:04<1:25:14, 154.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=208896, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 85.00 +/- 54.92\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 85           |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 208896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036329948 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.28e+04     |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.00043     |\n",
      "|    value_loss           | 3.02e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████▉                                                       | 212990/1000000 [31:36<1:15:17, 174.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=212992, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008155175 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.377      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.99e+03    |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | 0.00172     |\n",
      "|    value_loss           | 2.37e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████▏                                                      | 217079/1000000 [32:12<1:32:56, 140.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=217088, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 170.33 +/- 160.01\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 170        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 217088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00553675 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.367     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.77e+03   |\n",
      "|    n_updates            | 1050       |\n",
      "|    policy_gradient_loss | 0.00244    |\n",
      "|    value_loss           | 1.61e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████▍                                                      | 221180/1000000 [32:46<1:27:27, 148.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=221184, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.33 +/- 235.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 334         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016289618 |\n",
      "|    clip_fraction        | 0.0336      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.27e+03    |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | 0.000179    |\n",
      "|    value_loss           | 9.98e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████▊                                                      | 225280/1000000 [33:21<1:01:09, 211.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=225280, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 359.33 +/- 200.35\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 359        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 225280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00562965 |\n",
      "|    clip_fraction        | 0.0606     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 2.38e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.02e+03   |\n",
      "|    n_updates            | 1090       |\n",
      "|    policy_gradient_loss | 0.000338   |\n",
      "|    value_loss           | 8.38e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████                                                      | 229375/1000000 [33:57<1:27:12, 147.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=229376, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 212.33 +/- 204.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 212         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015436078 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | 0.00137     |\n",
      "|    value_loss           | 8.36e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████▎                                                     | 233466/1000000 [34:31<1:04:00, 199.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=233472, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 432.33 +/- 97.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 432          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 233472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034154663 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.316       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+03     |\n",
      "|    n_updates            | 1130         |\n",
      "|    policy_gradient_loss | 0.000404     |\n",
      "|    value_loss           | 8.34e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████▋                                                     | 237551/1000000 [35:08<1:04:21, 197.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=237568, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006639088 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.352      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3e+03       |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -5.19e-05   |\n",
      "|    value_loss           | 9.92e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████▉                                                     | 241659/1000000 [35:44<1:18:51, 160.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=241664, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043447977 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.32        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 779          |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.00031     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████▏                                                    | 245743/1000000 [36:20<1:09:03, 182.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=245760, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 457.33 +/- 61.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 457         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010813724 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.73e+03    |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | 0.00379     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████▍                                                    | 249846/1000000 [37:01<1:15:42, 165.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=249856, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 335.00 +/- 234.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010081462 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.354      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.78e+03    |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | 0.000369    |\n",
      "|    value_loss           | 1.15e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████▊                                                    | 253939/1000000 [37:39<1:27:30, 142.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=253952, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 104.33 +/- 74.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 104         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013706502 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.354      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.8e+03     |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.000115   |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████                                                    | 258042/1000000 [38:13<1:06:20, 186.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=258048, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 182.67 +/- 225.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 183         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010236589 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.376      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.61e+03    |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | 0.000215    |\n",
      "|    value_loss           | 1.46e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████▎                                                   | 262131/1000000 [38:50<1:14:28, 165.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=262144, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040728953 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.394      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.87e+03    |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | 0.00739     |\n",
      "|    value_loss           | 8.32e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████▋                                                   | 266235/1000000 [39:29<1:34:39, 129.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=266240, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036527752 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.354       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.32e+03     |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | -3.32e-05    |\n",
      "|    value_loss           | 8.31e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████▉                                                   | 270333/1000000 [40:04<1:07:08, 181.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=270336, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 448.67 +/- 74.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 449         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013584625 |\n",
      "|    clip_fraction        | 0.053       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.55e+03    |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.000185   |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████▊                                                    | 274419/1000000 [40:42<57:50, 209.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=274432, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049598187 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.46e+03    |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | 0.00257     |\n",
      "|    value_loss           | 7.21e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████▍                                                  | 278513/1000000 [41:17<1:11:05, 169.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=278528, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033176824 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.359      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.79e+03    |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | 0.00114     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████▎                                                   | 282616/1000000 [41:53<53:01, 225.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=282624, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 282624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056265565 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.367       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.7e+03      |\n",
      "|    n_updates            | 1370         |\n",
      "|    policy_gradient_loss | 0.00109      |\n",
      "|    value_loss           | 7.21e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████████████▋                                                   | 286720/1000000 [42:31<57:27, 206.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=286720, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 345.67 +/- 219.67\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 346         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008529156 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.21e+03    |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | 0.000916    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████████████▎                                                 | 290805/1000000 [43:06<1:27:28, 135.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=290816, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 430.00 +/- 100.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 430         |\n",
      "|    mean_reward          | 658         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005435356 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.369      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.9e+03     |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | 0.00216     |\n",
      "|    value_loss           | 8.8e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████▏                                                  | 294892/1000000 [43:44<57:50, 203.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=294912, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006757987 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.37e+03    |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | 0.00197     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████▉                                                 | 298996/1000000 [44:21<1:23:01, 140.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=299008, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 658          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085505005 |\n",
      "|    clip_fraction        | 0.0966       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.309       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.99e+03     |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | 0.00344      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████▊                                                  | 303098/1000000 [44:57<57:20, 202.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=303104, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008415364 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | 0.000903    |\n",
      "|    value_loss           | 7.23e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████▌                                                | 307196/1000000 [45:35<1:20:23, 143.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=307200, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 658         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016355548 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | 0.00462     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████▊                                                | 311291/1000000 [46:12<1:03:38, 180.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=311296, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 658          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 311296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060692756 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.252       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 1510         |\n",
      "|    policy_gradient_loss | 0.00372      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████▋                                                 | 315387/1000000 [46:49<56:05, 203.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=315392, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020413775 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.43e+03    |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | 0.000117    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████▎                                               | 319482/1000000 [47:27<1:05:19, 173.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=319488, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 471.67 +/- 41.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 472        |\n",
      "|    mean_reward          | 658        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 319488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07036618 |\n",
      "|    clip_fraction        | 0.0375     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.225     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 128        |\n",
      "|    n_updates            | 1550       |\n",
      "|    policy_gradient_loss | 0.00156    |\n",
      "|    value_loss           | 8.33e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████▋                                               | 323580/1000000 [48:07<1:19:39, 141.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=323584, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 658         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002417216 |\n",
      "|    clip_fraction        | 0.0265      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0877     |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 839         |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.000825   |\n",
      "|    value_loss           | 3.41e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████▉                                               | 327680/1000000 [48:47<1:19:20, 141.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=327680, episode_reward=460.00 +/- 325.27\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 460         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030037917 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.198      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.14e+03    |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | 0.00143     |\n",
      "|    value_loss           | 7.21e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████▉                                                | 331760/1000000 [49:28<55:44, 199.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=331776, episode_reward=460.00 +/- 325.27\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 460          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 331776       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012441523 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0653      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 417          |\n",
      "|    n_updates            | 1610         |\n",
      "|    policy_gradient_loss | -0.000634    |\n",
      "|    value_loss           | 3.82e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████▌                                              | 335867/1000000 [50:08<1:22:54, 133.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=335872, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048945982 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.135      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 558         |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    value_loss           | 4.96e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████▊                                              | 339956/1000000 [50:48<1:18:02, 140.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=339968, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 472           |\n",
      "|    mean_reward          | 856           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 339968        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084391347 |\n",
      "|    clip_fraction        | 0.091         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.264        |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.46e+03      |\n",
      "|    n_updates            | 1650          |\n",
      "|    policy_gradient_loss | 0.0032        |\n",
      "|    value_loss           | 8.34e+03      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████                                              | 344063/1000000 [51:29<1:15:08, 145.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=344064, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 344064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038128113 |\n",
      "|    clip_fraction        | 0.0914       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.308       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.12e+03     |\n",
      "|    n_updates            | 1670         |\n",
      "|    policy_gradient_loss | 0.000294     |\n",
      "|    value_loss           | 8.34e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████▎                                             | 348154/1000000 [52:07<1:19:34, 136.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=348160, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066265436 |\n",
      "|    clip_fraction        | 0.0758       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.315       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.48e+03     |\n",
      "|    n_updates            | 1690         |\n",
      "|    policy_gradient_loss | 0.000635     |\n",
      "|    value_loss           | 8.35e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████▎                                              | 352241/1000000 [52:47<51:02, 211.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=352256, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 352256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036412086 |\n",
      "|    clip_fraction        | 0.0914       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.291       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.75e+03     |\n",
      "|    n_updates            | 1710         |\n",
      "|    policy_gradient_loss | 0.00214      |\n",
      "|    value_loss           | 8.31e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████▋                                              | 356333/1000000 [53:28<55:57, 191.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=356352, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005233736 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.84e+03    |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | 9.83e-05    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████▉                                              | 360447/1000000 [54:07<48:03, 221.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=360448, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 360448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052879867 |\n",
      "|    clip_fraction        | 0.0948       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.301       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.59e+03     |\n",
      "|    n_updates            | 1750         |\n",
      "|    policy_gradient_loss | 0.00095      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████▏                                             | 364539/1000000 [54:47<57:38, 183.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=364544, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 364544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072697564 |\n",
      "|    clip_fraction        | 0.0637       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.299       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.15e+03     |\n",
      "|    n_updates            | 1770         |\n",
      "|    policy_gradient_loss | -0.00016     |\n",
      "|    value_loss           | 7.23e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████▊                                            | 368626/1000000 [55:28<1:08:47, 152.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=368640, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 472        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 368640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02341649 |\n",
      "|    clip_fraction        | 0.085      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.293     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.12e+03   |\n",
      "|    n_updates            | 1790       |\n",
      "|    policy_gradient_loss | 0.00135    |\n",
      "|    value_loss           | 7.66e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████▊                                             | 372726/1000000 [56:08<53:26, 195.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=372736, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 393.33 +/- 152.26\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 393        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 372736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17947413 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.259     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.23e+03   |\n",
      "|    n_updates            | 1810       |\n",
      "|    policy_gradient_loss | 0.00575    |\n",
      "|    value_loss           | 8.35e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████▍                                           | 376821/1000000 [56:46<1:01:49, 167.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=376832, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068726214 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.338       |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 1830         |\n",
      "|    policy_gradient_loss | -0.000282    |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████▍                                            | 380913/1000000 [57:26<49:53, 206.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=380928, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002169852 |\n",
      "|    clip_fraction        | 0.00757     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.45e+03    |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -2.08e-05   |\n",
      "|    value_loss           | 8.31e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████▉                                           | 385016/1000000 [58:05<1:09:50, 146.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=385024, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 335        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 385024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02967092 |\n",
      "|    clip_fraction        | 0.0521     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.311     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.17e+03   |\n",
      "|    n_updates            | 1870       |\n",
      "|    policy_gradient_loss | 0.00132    |\n",
      "|    value_loss           | 8.33e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████▏                                          | 389104/1000000 [58:42<1:21:53, 124.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=389120, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 335.00 +/- 234.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074473955 |\n",
      "|    clip_fraction        | 0.0645       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.363       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.98e+03     |\n",
      "|    n_updates            | 1890         |\n",
      "|    policy_gradient_loss | 4.46e-05     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████▎                                           | 393214/1000000 [59:21<48:35, 208.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=393216, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010969015 |\n",
      "|    clip_fraction        | 0.0725      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.389      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.64e+03    |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | 0.000212    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████▊                                          | 397297/1000000 [59:59<1:02:34, 160.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=397312, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 335        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 397312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02726917 |\n",
      "|    clip_fraction        | 0.0946     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.404     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.25e+03   |\n",
      "|    n_updates            | 1930       |\n",
      "|    policy_gradient_loss | 0.000406   |\n",
      "|    value_loss           | 8.33e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████▎                                        | 401396/1000000 [1:00:38<1:01:44, 161.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=401408, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.33 +/- 235.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 334         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007100203 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.84e+03    |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | 0.00474     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████▌                                        | 405502/1000000 [1:01:16<1:00:36, 163.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=405504, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008629781 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.361      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.63e+03    |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | 0.00135     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████▋                                         | 409592/1000000 [1:01:56<54:24, 180.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=409600, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011544742 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.363      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | 0.000665    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 109    |\n",
      "|    iterations      | 200    |\n",
      "|    time_elapsed    | 3726   |\n",
      "|    total_timesteps | 409600 |\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████▏                                       | 413679/1000000 [1:02:36<1:12:41, 134.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=413696, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005033674 |\n",
      "|    clip_fraction        | 0.0365      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.23e+03    |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -8.45e-05   |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████▏                                        | 417788/1000000 [1:03:16<50:38, 191.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=417792, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010131761 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.353      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -2.4e-05    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████▋                                       | 421874/1000000 [1:03:55<1:12:56, 132.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=421888, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016847948 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.54e+03    |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | 0.00114     |\n",
      "|    value_loss           | 8.34e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████▊                                        | 425979/1000000 [1:04:35<46:44, 204.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=425984, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007536783 |\n",
      "|    clip_fraction        | 0.0452      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.192      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.21e+03    |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | 0.000628    |\n",
      "|    value_loss           | 7.21e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████                                        | 430077/1000000 [1:05:12<49:46, 190.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=430080, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 430080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050308956 |\n",
      "|    clip_fraction        | 0.0663       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.216       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.04e+03     |\n",
      "|    n_updates            | 2090         |\n",
      "|    policy_gradient_loss | -6.66e-05    |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████▌                                      | 434174/1000000 [1:05:53<1:01:53, 152.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=434176, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020511165 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.67e+03    |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | 0.00295     |\n",
      "|    value_loss           | 7.2e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████▋                                       | 438267/1000000 [1:06:30<54:57, 170.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=438272, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 438272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037019022 |\n",
      "|    clip_fraction        | 0.0816       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.305       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.98e+03     |\n",
      "|    n_updates            | 2130         |\n",
      "|    policy_gradient_loss | 0.00111      |\n",
      "|    value_loss           | 8.35e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████                                      | 442360/1000000 [1:07:10<1:01:51, 150.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=442368, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 442368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031654912 |\n",
      "|    clip_fraction        | 0.0808       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.291       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.84e+03     |\n",
      "|    n_updates            | 2150         |\n",
      "|    policy_gradient_loss | 0.000733     |\n",
      "|    value_loss           | 7.21e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████▎                                     | 446448/1000000 [1:07:46<1:11:26, 129.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=446464, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 446464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076428554 |\n",
      "|    clip_fraction        | 0.0658       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.268       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.03e+03     |\n",
      "|    n_updates            | 2170         |\n",
      "|    policy_gradient_loss | 0.00105      |\n",
      "|    value_loss           | 7.23e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████▌                                      | 450546/1000000 [1:08:23<47:04, 194.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=450560, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010757317 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.321       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.94e+03     |\n",
      "|    n_updates            | 2190         |\n",
      "|    policy_gradient_loss | -8.72e-05    |\n",
      "|    value_loss           | 8.35e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████▊                                      | 454638/1000000 [1:09:00<52:27, 173.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=454656, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 412.67 +/- 124.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 413         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016420422 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | 0.000816    |\n",
      "|    value_loss           | 8.35e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████                                      | 458736/1000000 [1:09:37<40:38, 221.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=458752, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 418.67 +/- 116.44\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 419        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 458752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01236451 |\n",
      "|    clip_fraction        | 0.0603     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.386     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.37e+03   |\n",
      "|    n_updates            | 2230       |\n",
      "|    policy_gradient_loss | 0.00106    |\n",
      "|    value_loss           | 8.33e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████▍                                     | 462838/1000000 [1:10:14<42:04, 212.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=462848, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 462848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030535955 |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.388       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 2250         |\n",
      "|    policy_gradient_loss | 0.00286      |\n",
      "|    value_loss           | 8.31e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████▋                                     | 466930/1000000 [1:10:49<55:35, 159.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=466944, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011155738 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.333      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.04e+03    |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | 0.00296     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████                                    | 471040/1000000 [1:11:30<1:11:10, 123.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=471040, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012466001 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.56e+03    |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | 0.00213     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████▎                                   | 475129/1000000 [1:12:10<1:01:15, 142.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=475136, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 335        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 475136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01691895 |\n",
      "|    clip_fraction        | 0.0961     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.381     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.57e+03   |\n",
      "|    n_updates            | 2310       |\n",
      "|    policy_gradient_loss | 0.0025     |\n",
      "|    value_loss           | 8.33e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████▌                                    | 479217/1000000 [1:12:46<46:45, 185.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=479232, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 479232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051255757 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.385       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.39e+03     |\n",
      "|    n_updates            | 2330         |\n",
      "|    policy_gradient_loss | -7.37e-05    |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████▊                                   | 483320/1000000 [1:13:23<1:01:14, 140.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=483328, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 483328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019108693 |\n",
      "|    clip_fraction        | 0.0833       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.333       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.13e+03     |\n",
      "|    n_updates            | 2350         |\n",
      "|    policy_gradient_loss | 0.000753     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████                                    | 487406/1000000 [1:14:00<52:10, 163.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=487424, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.33 +/- 235.70\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 334          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 487424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063298536 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.339       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.39e+03     |\n",
      "|    n_updates            | 2370         |\n",
      "|    policy_gradient_loss | 0.000781     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████▍                                   | 491506/1000000 [1:14:38<42:44, 198.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=491520, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010834776 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.02e+03    |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | 0.00181     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████▋                                  | 495600/1000000 [1:15:16<1:05:11, 128.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=495616, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.33 +/- 235.70\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 334          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 495616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031198738 |\n",
      "|    clip_fraction        | 0.0544       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.309       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.93e+03     |\n",
      "|    n_updates            | 2410         |\n",
      "|    policy_gradient_loss | 0.000342     |\n",
      "|    value_loss           | 7.19e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████▉                                   | 499693/1000000 [1:15:52<40:39, 205.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=499712, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017544756 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.43e+03    |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | 0.0012      |\n",
      "|    value_loss           | 8.35e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████▎                                  | 503804/1000000 [1:16:30<41:35, 198.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=503808, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 503808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107149985 |\n",
      "|    clip_fraction        | 0.0938       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.372       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.6e+03      |\n",
      "|    n_updates            | 2450         |\n",
      "|    policy_gradient_loss | -0.000353    |\n",
      "|    value_loss           | 8.34e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████▌                                  | 507895/1000000 [1:17:08<40:41, 201.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=507904, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006171464 |\n",
      "|    clip_fraction        | 0.0684      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.22e+03    |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | 7.24e-05    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████▊                                  | 511985/1000000 [1:17:46<50:42, 160.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=512000, episode_reward=757.00 +/- 548.84\n",
      "Episode length: 445.00 +/- 79.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 445         |\n",
      "|    mean_reward          | 757         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014026309 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.09e+03    |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | 0.00152     |\n",
      "|    value_loss           | 8.35e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████▏                                 | 516095/1000000 [1:18:23<40:16, 200.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=516096, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009517066 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.399      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+04    |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | 0.00255     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████▍                                 | 520191/1000000 [1:19:02<59:57, 133.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=520192, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 520192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039857775 |\n",
      "|    clip_fraction        | 0.0729       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.39        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.36e+03     |\n",
      "|    n_updates            | 2530         |\n",
      "|    policy_gradient_loss | -1.78e-05    |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████▋                                 | 524288/1000000 [1:19:41<49:32, 160.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=524288, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001242176 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.63e+03    |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | 0.000457    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████████████████████▉                                 | 528374/1000000 [1:20:20<41:42, 188.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=528384, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001647119 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.85e+03    |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | 0.00057     |\n",
      "|    value_loss           | 8.17e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████▎                                | 532471/1000000 [1:20:59<43:36, 178.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=532480, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011554071 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.14e+03    |\n",
      "|    n_updates            | 2590        |\n",
      "|    policy_gradient_loss | 0.0012      |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████████████▌                                | 536555/1000000 [1:21:36<41:02, 188.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=536576, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 472        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 536576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00406198 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.307     |\n",
      "|    explained_variance   | -2.38e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.35e+03   |\n",
      "|    n_updates            | 2610       |\n",
      "|    policy_gradient_loss | 0.00226    |\n",
      "|    value_loss           | 8.33e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████████████▊                                | 540651/1000000 [1:22:13<38:00, 201.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=540672, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003144503 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.02e+03    |\n",
      "|    n_updates            | 2630        |\n",
      "|    policy_gradient_loss | 0.00107     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████▏                               | 544766/1000000 [1:22:49<46:20, 163.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=544768, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011258045 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.69e+03    |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | 0.000928    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████▍                               | 548850/1000000 [1:23:25<46:21, 162.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=548864, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027371775 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.37e+03    |\n",
      "|    n_updates            | 2670        |\n",
      "|    policy_gradient_loss | 0.000521    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████▋                               | 552958/1000000 [1:24:01<48:33, 153.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=552960, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 552960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011356899 |\n",
      "|    clip_fraction        | 0.0891       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.357       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.1e+03      |\n",
      "|    n_updates            | 2690         |\n",
      "|    policy_gradient_loss | 0.000294     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████▉                               | 557051/1000000 [1:24:38<50:26, 146.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=557056, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026447725 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.346      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.72e+03    |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | 0.00207     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████▎                              | 561152/1000000 [1:25:15<38:10, 191.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=561152, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 561152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015288134 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.311       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.37e+03     |\n",
      "|    n_updates            | 2730         |\n",
      "|    policy_gradient_loss | 0.00291      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████▌                              | 565243/1000000 [1:25:52<44:59, 161.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=565248, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 565248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033898572 |\n",
      "|    clip_fraction        | 0.0386       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.364       |\n",
      "|    explained_variance   | 2.38e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.17e+03     |\n",
      "|    n_updates            | 2750         |\n",
      "|    policy_gradient_loss | -8.48e-05    |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████▊                              | 569338/1000000 [1:26:29<47:00, 152.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=569344, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006571437 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.04e+03    |\n",
      "|    n_updates            | 2770        |\n",
      "|    policy_gradient_loss | 0.000515    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████▏                             | 573435/1000000 [1:27:04<46:34, 152.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=573440, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.33 +/- 235.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 334         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011475545 |\n",
      "|    clip_fraction        | 0.0377      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | 0.000454    |\n",
      "|    value_loss           | 8.35e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████▍                             | 577527/1000000 [1:27:39<37:34, 187.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=577536, episode_reward=954.33 +/- 466.22\n",
      "Episode length: 496.33 +/- 6.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 496          |\n",
      "|    mean_reward          | 954          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 577536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036907964 |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.23e+03     |\n",
      "|    n_updates            | 2810         |\n",
      "|    policy_gradient_loss | 0.00343      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████▋                             | 581624/1000000 [1:28:16<39:32, 176.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=581632, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 335        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 581632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08261572 |\n",
      "|    clip_fraction        | 0.0893     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.404     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.07e+04   |\n",
      "|    n_updates            | 2830       |\n",
      "|    policy_gradient_loss | 0.000601   |\n",
      "|    value_loss           | 9.94e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████████████████████▉                             | 585714/1000000 [1:28:51<33:00, 209.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=585728, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 476.33 +/- 34.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 476          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 585728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077290135 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.385       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.58e+03     |\n",
      "|    n_updates            | 2850         |\n",
      "|    policy_gradient_loss | 1.94e-05     |\n",
      "|    value_loss           | 9.96e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████████████████████████████▎                            | 589821/1000000 [1:29:29<44:07, 154.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=589824, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007955121 |\n",
      "|    clip_fraction        | 0.0509      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.362      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.74e+03    |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.00082    |\n",
      "|    value_loss           | 8.31e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████████████████████████████▌                            | 593912/1000000 [1:30:04<41:12, 164.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=593920, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 220.00 +/- 208.78\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 220          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 593920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018222792 |\n",
      "|    clip_fraction        | 0.0464       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.398       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.91e+03     |\n",
      "|    n_updates            | 2890         |\n",
      "|    policy_gradient_loss | 0.000318     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████▊                            | 598005/1000000 [1:30:38<44:35, 150.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=598016, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.33 +/- 235.70\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 334        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 598016     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01219576 |\n",
      "|    clip_fraction        | 0.0958     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.447     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.45e+03   |\n",
      "|    n_updates            | 2910       |\n",
      "|    policy_gradient_loss | 0.00195    |\n",
      "|    value_loss           | 8.34e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████▏                           | 602105/1000000 [1:31:13<43:13, 153.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=602112, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 602112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018204777 |\n",
      "|    clip_fraction        | 0.0407       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.426       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.53e+03     |\n",
      "|    n_updates            | 2930         |\n",
      "|    policy_gradient_loss | -1.34e-05    |\n",
      "|    value_loss           | 8.34e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████▍                           | 606204/1000000 [1:31:50<43:39, 150.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=606208, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013515522 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.374      |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.39e+03    |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | 0.0012      |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████▋                           | 610294/1000000 [1:32:26<41:55, 154.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=610304, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 610304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010372434 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.88e+03    |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | 0.00483     |\n",
      "|    value_loss           | 8.31e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████                           | 614393/1000000 [1:33:04<41:39, 154.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=614400, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 614400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030371058 |\n",
      "|    clip_fraction        | 0.0439       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.363       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.04e+03     |\n",
      "|    n_updates            | 2990         |\n",
      "|    policy_gradient_loss | -0.000497    |\n",
      "|    value_loss           | 8.34e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████▎                          | 618477/1000000 [1:33:39<40:42, 156.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=618496, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009079516 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.381      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.25e+03    |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | -0.000165   |\n",
      "|    value_loss           | 8.34e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████▌                          | 622592/1000000 [1:34:15<34:37, 181.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=622592, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 622592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010488867 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.34        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.3e+03      |\n",
      "|    n_updates            | 3030         |\n",
      "|    policy_gradient_loss | 0.00057      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████▊                          | 626676/1000000 [1:34:52<37:16, 166.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=626688, episode_reward=757.00 +/- 548.84\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 757         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003286623 |\n",
      "|    clip_fraction        | 0.0552      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.04e+03    |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | 0.000747    |\n",
      "|    value_loss           | 7.66e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████████████████████████▏                         | 630778/1000000 [1:35:29<33:21, 184.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=630784, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 630784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022875448 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.337       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 3070         |\n",
      "|    policy_gradient_loss | 0.00165      |\n",
      "|    value_loss           | 7.21e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|████████████████████████████████████████████▍                         | 634877/1000000 [1:36:06<32:52, 185.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=634880, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006150388 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 2.38e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.34e+03    |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | 8.45e-05    |\n",
      "|    value_loss           | 8.31e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████▋                         | 638973/1000000 [1:36:43<32:38, 184.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=638976, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003988956 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.21e+03    |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | 0.00081     |\n",
      "|    value_loss           | 8.31e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████████████████████████                         | 643070/1000000 [1:37:20<30:07, 197.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=643072, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008969022 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+04    |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | 0.000296    |\n",
      "|    value_loss           | 6.81e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████▎                        | 647159/1000000 [1:37:54<33:50, 173.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=647168, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 472        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 647168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00495194 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.31      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.71e+03   |\n",
      "|    n_updates            | 3150       |\n",
      "|    policy_gradient_loss | 0.00158    |\n",
      "|    value_loss           | 8.35e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████▌                        | 651255/1000000 [1:38:32<38:47, 149.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=651264, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 651264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010729036 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.59e+03    |\n",
      "|    n_updates            | 3170        |\n",
      "|    policy_gradient_loss | 0.000411    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████▊                        | 655347/1000000 [1:39:07<37:13, 154.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=655360, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016048474 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.65e+03    |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | 0.00111     |\n",
      "|    value_loss           | 8.35e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████▏                       | 659444/1000000 [1:39:42<33:19, 170.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=659456, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007975182 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.376      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.92e+03    |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | 0.00015     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████▍                       | 663541/1000000 [1:40:19<34:07, 164.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=663552, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 663552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061301575 |\n",
      "|    clip_fraction        | 0.0929       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 3230         |\n",
      "|    policy_gradient_loss | 0.000693     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████▋                       | 667632/1000000 [1:40:54<29:10, 189.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=667648, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019895406 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.371      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.85e+03    |\n",
      "|    n_updates            | 3250        |\n",
      "|    policy_gradient_loss | -0.000168   |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████                       | 671727/1000000 [1:41:31<35:52, 152.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=671744, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 671744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037034042 |\n",
      "|    clip_fraction        | 0.0913       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.362       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.39e+03     |\n",
      "|    n_updates            | 3270         |\n",
      "|    policy_gradient_loss | 0.00193      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████▎                      | 675832/1000000 [1:42:08<31:36, 170.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=675840, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006345403 |\n",
      "|    clip_fraction        | 0.0733      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.396      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 337         |\n",
      "|    n_updates            | 3290        |\n",
      "|    policy_gradient_loss | 0.000297    |\n",
      "|    value_loss           | 6.79e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████▌                      | 679934/1000000 [1:42:44<28:53, 184.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=679936, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 679936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055248765 |\n",
      "|    clip_fraction        | 0.0603       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.386       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.42e+03     |\n",
      "|    n_updates            | 3310         |\n",
      "|    policy_gradient_loss | -7.65e-05    |\n",
      "|    value_loss           | 8.31e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████▉                      | 684027/1000000 [1:43:21<26:38, 197.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=684032, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 249.33 +/- 204.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 249         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014888512 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.376      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.79e+03    |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | 0.000445    |\n",
      "|    value_loss           | 8.35e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████▏                     | 688111/1000000 [1:43:55<26:39, 194.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=688128, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 214.33 +/- 210.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 214         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012152638 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.385      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.27e+03    |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -0.000333   |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████▍                     | 692211/1000000 [1:44:28<29:44, 172.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=692224, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 376.33 +/- 176.31\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 376        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 692224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02139531 |\n",
      "|    clip_fraction        | 0.0614     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.386     |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.01e+03   |\n",
      "|    n_updates            | 3370       |\n",
      "|    policy_gradient_loss | 0.00099    |\n",
      "|    value_loss           | 8.33e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████▋                     | 696302/1000000 [1:45:05<26:00, 194.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=696320, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 696320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039574215 |\n",
      "|    clip_fraction        | 0.056        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 130          |\n",
      "|    n_updates            | 3390         |\n",
      "|    policy_gradient_loss | 0.000115     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████                     | 700404/1000000 [1:45:40<33:14, 150.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=700416, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 365.00 +/- 98.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 365          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 700416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037827287 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+03     |\n",
      "|    n_updates            | 3410         |\n",
      "|    policy_gradient_loss | 0.00224      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████▎                    | 704509/1000000 [1:46:16<23:08, 212.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=704512, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 704512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068654483 |\n",
      "|    clip_fraction        | 0.0877       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.69e+03     |\n",
      "|    n_updates            | 3430         |\n",
      "|    policy_gradient_loss | -0.000111    |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████▌                    | 708606/1000000 [1:46:52<23:30, 206.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=708608, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 708608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012299533 |\n",
      "|    clip_fraction        | 0.0675       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.397       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.1e+03      |\n",
      "|    n_updates            | 3450         |\n",
      "|    policy_gradient_loss | 0.000542     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████▉                    | 712701/1000000 [1:47:31<34:38, 138.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=712704, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015697032 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.402      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.71e+03    |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | 0.000188    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████▏                   | 716788/1000000 [1:48:07<26:38, 177.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=716800, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 716800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023423259 |\n",
      "|    clip_fraction        | 0.0526       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 2.38e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.53e+03     |\n",
      "|    n_updates            | 3490         |\n",
      "|    policy_gradient_loss | 0.000775     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████▍                   | 720878/1000000 [1:48:45<36:50, 126.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=720896, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 455.00 +/- 65.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 455         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020970583 |\n",
      "|    clip_fraction        | 0.0696      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.397      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.05e+03    |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.000276   |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████▋                   | 724992/1000000 [1:49:23<23:14, 197.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=724992, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 724992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022878512 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.355       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.14e+03     |\n",
      "|    n_updates            | 3530         |\n",
      "|    policy_gradient_loss | -0.000208    |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████████████████████████████████                   | 729067/1000000 [1:49:58<21:20, 211.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=729088, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010228977 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.25e+03    |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | 0.00184     |\n",
      "|    value_loss           | 7.21e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████████████████████████████████▎                  | 733163/1000000 [1:50:34<21:05, 210.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=733184, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008539954 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.333      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.55e+03    |\n",
      "|    n_updates            | 3570        |\n",
      "|    policy_gradient_loss | -3.66e-05   |\n",
      "|    value_loss           | 8.31e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████▌                  | 737273/1000000 [1:51:12<25:39, 170.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=737280, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 658         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008531082 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.24e+03    |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | 0.000296    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████▉                  | 741363/1000000 [1:51:53<22:10, 194.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=741376, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 741376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055296484 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.26       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | 0.00199     |\n",
      "|    value_loss           | 6.09e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████▏                 | 745466/1000000 [1:52:32<28:30, 148.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=745472, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007769012 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.353      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -7.73e-05   |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████▍                 | 749549/1000000 [1:53:08<30:48, 135.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=749568, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 749568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063682673 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.257       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.74e+03     |\n",
      "|    n_updates            | 3650         |\n",
      "|    policy_gradient_loss | 0.000126     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████▊                 | 753654/1000000 [1:53:47<27:32, 149.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=753664, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017368972 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.44e+03    |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | 0.000229    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████                 | 757753/1000000 [1:54:25<30:41, 131.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=757760, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009762613 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.13e+03    |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | 0.00116     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████▎                | 761850/1000000 [1:55:03<26:06, 152.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=761856, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 761856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031155306 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.332       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 119          |\n",
      "|    n_updates            | 3710         |\n",
      "|    policy_gradient_loss | 0.000214     |\n",
      "|    value_loss           | 8.31e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████▌                | 765951/1000000 [1:55:41<26:31, 147.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=765952, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 416.00 +/- 120.21\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 416          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 765952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016617044 |\n",
      "|    clip_fraction        | 0.0661       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.378       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.37e+03     |\n",
      "|    n_updates            | 3730         |\n",
      "|    policy_gradient_loss | 0.000325     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████▉                | 770034/1000000 [1:56:18<20:01, 191.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=770048, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 770048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029252826 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.326       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 3750         |\n",
      "|    policy_gradient_loss | -0.000141    |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████▏               | 774130/1000000 [1:56:58<27:39, 136.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=774144, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.33 +/- 235.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 334         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005411125 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48e+03    |\n",
      "|    n_updates            | 3770        |\n",
      "|    policy_gradient_loss | 0.00104     |\n",
      "|    value_loss           | 8.31e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████▍               | 778235/1000000 [1:57:34<25:00, 147.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=778240, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 401.33 +/- 86.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 401         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011843728 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.365      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.18e+03    |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | 0.00192     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████▊               | 782330/1000000 [1:58:13<21:50, 166.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=782336, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 387.67 +/- 160.28\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 388        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 782336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05841942 |\n",
      "|    clip_fraction        | 0.0768     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.387     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.95e+03   |\n",
      "|    n_updates            | 3810       |\n",
      "|    policy_gradient_loss | 0.000847   |\n",
      "|    value_loss           | 8.31e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████               | 786421/1000000 [1:58:51<24:11, 147.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=786432, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 446.33 +/- 77.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 446          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 786432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032744438 |\n",
      "|    clip_fraction        | 0.062        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.384       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.1e+03      |\n",
      "|    n_updates            | 3830         |\n",
      "|    policy_gradient_loss | 0.000709     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████▎              | 790527/1000000 [1:59:28<18:10, 192.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=790528, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 316.33 +/- 156.19\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 316          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 790528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026957628 |\n",
      "|    clip_fraction        | 0.0502       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.362       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 3850         |\n",
      "|    policy_gradient_loss | 0.000304     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████▌              | 794614/1000000 [2:00:05<16:34, 206.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=794624, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002349386 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.382      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.01e+03    |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | 0.000158    |\n",
      "|    value_loss           | 7.21e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████▉              | 798707/1000000 [2:00:43<20:12, 165.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=798720, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 472        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 798720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00604723 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.389     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.37e+03   |\n",
      "|    n_updates            | 3890       |\n",
      "|    policy_gradient_loss | 0.000216   |\n",
      "|    value_loss           | 8.33e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████▏             | 802792/1000000 [2:01:22<14:49, 221.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=802816, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 658         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008416964 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.384      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.14e+03    |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | 0.00125     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████▍             | 806898/1000000 [2:02:01<23:27, 137.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=806912, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013813183 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.383      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | 0.000894    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████▊             | 811002/1000000 [2:02:40<18:47, 167.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=811008, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 811008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047812136 |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.355       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.95e+03     |\n",
      "|    n_updates            | 3950         |\n",
      "|    policy_gradient_loss | 0.000186     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████             | 815093/1000000 [2:03:19<20:42, 148.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=815104, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 815104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065544457 |\n",
      "|    clip_fraction        | 0.0909       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.352       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 3970         |\n",
      "|    policy_gradient_loss | 0.00108      |\n",
      "|    value_loss           | 8.34e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████▎            | 819197/1000000 [2:03:59<20:18, 148.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=819200, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.33 +/- 235.70\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 334        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 819200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01961973 |\n",
      "|    clip_fraction        | 0.0814     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.265     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.79e+03   |\n",
      "|    n_updates            | 3990       |\n",
      "|    policy_gradient_loss | 0.000611   |\n",
      "|    value_loss           | 8.34e+03   |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 109    |\n",
      "|    iterations      | 400    |\n",
      "|    time_elapsed    | 7447   |\n",
      "|    total_timesteps | 819200 |\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████▋            | 823286/1000000 [2:04:40<21:12, 138.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=823296, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013524032 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 752         |\n",
      "|    n_updates            | 4010        |\n",
      "|    policy_gradient_loss | 0.000957    |\n",
      "|    value_loss           | 8.34e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████▉            | 827385/1000000 [2:05:21<16:29, 174.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=827392, episode_reward=757.00 +/- 548.84\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 757          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 827392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019302348 |\n",
      "|    clip_fraction        | 0.0679       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.316       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.59e+03     |\n",
      "|    n_updates            | 4030         |\n",
      "|    policy_gradient_loss | 0.00208      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████▏           | 831481/1000000 [2:05:58<12:39, 221.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=831488, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 831488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020886266 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.327       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.45e+03     |\n",
      "|    n_updates            | 4050         |\n",
      "|    policy_gradient_loss | 0.000302     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████▍           | 835579/1000000 [2:06:38<17:02, 160.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=835584, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 835584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062315864 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.322       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.44e+03     |\n",
      "|    n_updates            | 4070         |\n",
      "|    policy_gradient_loss | -0.000317    |\n",
      "|    value_loss           | 8.31e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████▊           | 839670/1000000 [2:07:16<20:13, 132.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=839680, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006125965 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.43e+03    |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | 0.000138    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████           | 843776/1000000 [2:07:55<20:07, 129.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=843776, episode_reward=757.00 +/- 548.84\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 757         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015086823 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.47e+03    |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | 0.000748    |\n",
      "|    value_loss           | 7.21e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████▎          | 847851/1000000 [2:08:32<11:54, 213.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=847872, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 471.67 +/- 41.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 472        |\n",
      "|    mean_reward          | 658        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 847872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07784647 |\n",
      "|    clip_fraction        | 0.0596     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.262     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.03e+03   |\n",
      "|    n_updates            | 4130       |\n",
      "|    policy_gradient_loss | 0.00166    |\n",
      "|    value_loss           | 7.67e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████▋          | 851965/1000000 [2:09:12<17:43, 139.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=851968, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 363.00 +/- 195.16\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 363        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 851968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01682994 |\n",
      "|    clip_fraction        | 0.07       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.402     |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.48e+03   |\n",
      "|    n_updates            | 4150       |\n",
      "|    policy_gradient_loss | -0.000402  |\n",
      "|    value_loss           | 8.33e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████▉          | 856049/1000000 [2:09:48<16:47, 142.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=856064, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 856064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024285768 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.333       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.28e+03     |\n",
      "|    n_updates            | 4170         |\n",
      "|    policy_gradient_loss | -0.000312    |\n",
      "|    value_loss           | 7.21e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████▏         | 860145/1000000 [2:10:25<11:51, 196.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=860160, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 860160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008183438 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.335       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.31e+03     |\n",
      "|    n_updates            | 4190         |\n",
      "|    policy_gradient_loss | -3.91e-05    |\n",
      "|    value_loss           | 8.31e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████▍         | 864253/1000000 [2:11:03<11:08, 203.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=864256, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 864256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033339171 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.321       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.76e+03     |\n",
      "|    n_updates            | 4210         |\n",
      "|    policy_gradient_loss | 0.000164     |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████████████████████████████████████████████████████████▊         | 868341/1000000 [2:11:41<11:14, 195.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=868352, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 868352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024033133 |\n",
      "|    clip_fraction        | 0.0942       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.313       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02e+04     |\n",
      "|    n_updates            | 4230         |\n",
      "|    policy_gradient_loss | 0.00159      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████         | 872448/1000000 [2:12:21<14:08, 150.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=872448, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 472        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 872448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00716901 |\n",
      "|    clip_fraction        | 0.084      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.362     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.13e+03   |\n",
      "|    n_updates            | 4250       |\n",
      "|    policy_gradient_loss | 0.000626   |\n",
      "|    value_loss           | 8.35e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████████████████████████▎        | 876526/1000000 [2:13:01<15:33, 132.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=876544, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019521685 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.346      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | 0.000734    |\n",
      "|    value_loss           | 8.32e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████████████████████████▋        | 880635/1000000 [2:13:40<15:05, 131.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=880640, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 425.33 +/- 57.41\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 425          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 880640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060634734 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.364       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.64e+03     |\n",
      "|    n_updates            | 4290         |\n",
      "|    policy_gradient_loss | -9.92e-05    |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████████████████████████▉        | 884733/1000000 [2:14:17<11:02, 173.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=884736, episode_reward=757.00 +/- 548.84\n",
      "Episode length: 341.00 +/- 167.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 341         |\n",
      "|    mean_reward          | 757         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030500235 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.369      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 971         |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | 0.000518    |\n",
      "|    value_loss           | 8.35e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████████████████████████████████▏       | 888814/1000000 [2:14:54<10:08, 182.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=888832, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002122474 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.88e+03    |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.00042    |\n",
      "|    value_loss           | 5.89e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████████████████████████████████▌       | 892914/1000000 [2:15:33<12:31, 142.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=892928, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 323.00 +/- 130.67\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 323         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021429814 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.34e+03    |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | 0.000765    |\n",
      "|    value_loss           | 7.21e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████▊       | 897004/1000000 [2:16:12<08:55, 192.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=897024, episode_reward=757.00 +/- 548.84\n",
      "Episode length: 340.67 +/- 226.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 341         |\n",
      "|    mean_reward          | 757         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022111237 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.78e+03    |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | 0.000925    |\n",
      "|    value_loss           | 7.66e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████       | 901119/1000000 [2:16:48<10:39, 154.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=901120, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059814468 |\n",
      "|    clip_fraction        | 0.0742      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.9e+03     |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | 0.00155     |\n",
      "|    value_loss           | 8.31e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|███████████████████████████████████████████████████████████████▎      | 905203/1000000 [2:17:28<08:35, 183.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=905216, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 394.33 +/- 150.85\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 394          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 905216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029301583 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.316       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+03     |\n",
      "|    n_updates            | 4410         |\n",
      "|    policy_gradient_loss | -4.76e-07    |\n",
      "|    value_loss           | 8.31e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|███████████████████████████████████████████████████████████████▋      | 909302/1000000 [2:18:05<07:45, 194.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=909312, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 369.33 +/- 129.08\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 369        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 909312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00718056 |\n",
      "|    clip_fraction        | 0.0597     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.34      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.82e+03   |\n",
      "|    n_updates            | 4430       |\n",
      "|    policy_gradient_loss | 0.000313   |\n",
      "|    value_loss           | 8.33e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|███████████████████████████████████████████████████████████████▉      | 913402/1000000 [2:18:43<09:35, 150.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=913408, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 349.00 +/- 214.96\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 349       |\n",
      "|    mean_reward          | 856       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 913408    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0091959 |\n",
      "|    clip_fraction        | 0.0722    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.345    |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.44e+03  |\n",
      "|    n_updates            | 4450      |\n",
      "|    policy_gradient_loss | -0.000308 |\n",
      "|    value_loss           | 8.33e+03  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████████████████████████████████▏     | 917494/1000000 [2:19:22<10:47, 127.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=917504, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 340.00 +/- 227.69\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 340        |\n",
      "|    mean_reward          | 856        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 917504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01769505 |\n",
      "|    clip_fraction        | 0.0588     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.287     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.36e+03   |\n",
      "|    n_updates            | 4470       |\n",
      "|    policy_gradient_loss | 0.00149    |\n",
      "|    value_loss           | 8.35e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████████████████████████████████▌     | 921595/1000000 [2:19:59<09:59, 130.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=921600, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 267.67 +/- 199.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 268          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 921600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016843694 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.269       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.07e+03     |\n",
      "|    n_updates            | 4490         |\n",
      "|    policy_gradient_loss | 0.00109      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████▊     | 925690/1000000 [2:20:35<06:01, 205.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=925696, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 925696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036675879 |\n",
      "|    clip_fraction        | 0.0493       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.312       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.69e+03     |\n",
      "|    n_updates            | 4510         |\n",
      "|    policy_gradient_loss | -0.000607    |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████     | 929781/1000000 [2:21:14<06:09, 190.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=929792, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009680256 |\n",
      "|    clip_fraction        | 0.0397      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.27e+03    |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | 0.000115    |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████▎    | 933876/1000000 [2:21:54<08:17, 132.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=933888, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 417.00 +/- 118.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 417          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 933888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077640936 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.315       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.59e+03     |\n",
      "|    n_updates            | 4550         |\n",
      "|    policy_gradient_loss | 0.000121     |\n",
      "|    value_loss           | 8.31e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████▋    | 937979/1000000 [2:22:33<06:37, 156.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=937984, episode_reward=658.00 +/- 524.68\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 658          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 937984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005502021 |\n",
      "|    clip_fraction        | 0.069        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.306       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.08e+03     |\n",
      "|    n_updates            | 4570         |\n",
      "|    policy_gradient_loss | 0.00134      |\n",
      "|    value_loss           | 8.34e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████▉    | 942066/1000000 [2:23:12<06:10, 156.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=942080, episode_reward=854.67 +/- 604.34\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 855         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004141441 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 4590        |\n",
      "|    policy_gradient_loss | 0.000803    |\n",
      "|    value_loss           | 5.83e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████████████████████████████████▏   | 946173/1000000 [2:23:52<06:08, 146.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=946176, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 946176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037345397 |\n",
      "|    clip_fraction        | 0.0718       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.349       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.73e+03     |\n",
      "|    n_updates            | 4610         |\n",
      "|    policy_gradient_loss | -0.000258    |\n",
      "|    value_loss           | 8.31e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████████████████████████████████▌   | 950255/1000000 [2:24:31<05:35, 148.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=950272, episode_reward=757.00 +/- 548.84\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 757          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 950272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025297028 |\n",
      "|    clip_fraction        | 0.0718       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.341       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 975          |\n",
      "|    n_updates            | 4630         |\n",
      "|    policy_gradient_loss | 0.00028      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████████████████████████████████▊   | 954354/1000000 [2:25:11<04:00, 190.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=954368, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003858375 |\n",
      "|    clip_fraction        | 0.0733      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+03     |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | 0.000354    |\n",
      "|    value_loss           | 8.31e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████████████████████████████████   | 958455/1000000 [2:25:50<03:53, 178.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=958464, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 391.33 +/- 122.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 391          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 958464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045879716 |\n",
      "|    clip_fraction        | 0.0719       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.332       |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.72e+03     |\n",
      "|    n_updates            | 4670         |\n",
      "|    policy_gradient_loss | 0.000142     |\n",
      "|    value_loss           | 8.34e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████████████████████████████████▍  | 962552/1000000 [2:26:29<03:30, 177.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=962560, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 452.33 +/- 68.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 452          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 962560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127961375 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.69e+03     |\n",
      "|    n_updates            | 4690         |\n",
      "|    policy_gradient_loss | 0.00015      |\n",
      "|    value_loss           | 8.33e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████▋  | 966654/1000000 [2:27:10<03:42, 149.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=966656, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 287.67 +/- 196.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 288         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011184542 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.424      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.1e+03     |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | 0.000272    |\n",
      "|    value_loss           | 8.35e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████▉  | 970742/1000000 [2:27:46<02:53, 168.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=970752, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 970752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007128802 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.431      |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.7e+03     |\n",
      "|    n_updates            | 4730        |\n",
      "|    policy_gradient_loss | 0.000755    |\n",
      "|    value_loss           | 7.65e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|████████████████████████████████████████████████████████████████████▏ | 974830/1000000 [2:28:25<03:00, 139.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=974848, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.67 +/- 235.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 335          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 974848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057797935 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.346       |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.39e+03     |\n",
      "|    n_updates            | 4750         |\n",
      "|    policy_gradient_loss | -0.000691    |\n",
      "|    value_loss           | 7.21e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████▌ | 978936/1000000 [2:29:04<02:19, 150.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=978944, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | 856         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009755866 |\n",
      "|    clip_fraction        | 0.0881      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.388      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | 0.00078     |\n",
      "|    value_loss           | 8.33e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████▊ | 983029/1000000 [2:29:43<01:26, 196.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=983040, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 983040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074238004 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.34        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.18e+03     |\n",
      "|    n_updates            | 4790         |\n",
      "|    policy_gradient_loss | 0.00142      |\n",
      "|    value_loss           | 4.95e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████ | 987132/1000000 [2:30:24<01:33, 137.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=987136, episode_reward=757.00 +/- 548.84\n",
      "Episode length: 314.33 +/- 222.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 314         |\n",
      "|    mean_reward          | 757         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030541912 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.08e+03    |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | 0.00137     |\n",
      "|    value_loss           | 8.31e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████▍| 991227/1000000 [2:31:02<00:44, 198.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=991232, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 334.33 +/- 235.70\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 334          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 991232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054142964 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.344       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.44e+03     |\n",
      "|    n_updates            | 4830         |\n",
      "|    policy_gradient_loss | 2.21e-05     |\n",
      "|    value_loss           | 8.32e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████▋| 995318/1000000 [2:31:39<00:21, 219.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=995328, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 995328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020243428 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.22e+03     |\n",
      "|    n_updates            | 4850         |\n",
      "|    policy_gradient_loss | -0.000238    |\n",
      "|    value_loss           | 8.35e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████▉| 999411/1000000 [2:32:18<00:03, 182.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=999424, episode_reward=856.00 +/- 605.28\n",
      "Episode length: 471.67 +/- 41.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 472          |\n",
      "|    mean_reward          | 856          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 999424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043853605 |\n",
      "|    clip_fraction        | 0.0664       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.317       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.65e+03     |\n",
      "|    n_updates            | 4870         |\n",
      "|    policy_gradient_loss | 0.000264     |\n",
      "|    value_loss           | 7.66e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001472it [2:32:43, 109.28it/s]                                                                                        \n"
     ]
    }
   ],
   "source": [
    "# del modelPPO\n",
    "# del model\n",
    "\n",
    "\n",
    "save_path = os.path.join('Dissertacao','Training_BoxConveyor','Model_saves','PPO_B03')\n",
    "#policy_kwargs = dict(activation_fn=th.nn.Tanh)\n",
    "#policy_kwargs = dict(activation_fn=th.nn.Tanh,\n",
    " #                    net_arch=[dict(pi=[300,300,300], vf=[300,300,300])])\n",
    "log_path = os.path.join('Dissertacao','Training_BoxConveyor','Logs','PPO_B03')\n",
    "env=DrillEnv()\n",
    "env.setprint(False)\n",
    "env=DummyVecEnv([lambda: env])\n",
    "env.reset()\n",
    "\n",
    "modelPPO=PPO('MlpPolicy',env,verbose=1,\n",
    "             #n_steps=5000,\n",
    "             gamma=0.95, gae_lambda=0.90,\n",
    "             seed=9,#policy_kwargs=policy_kwargs,\n",
    "             tensorboard_log=log_path)\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "  save_freq=10000,\n",
    "  save_path=os.path.join('Dissertacao','Training_BoxConveyor','Model_saves','PPO_B03_backup') ,\n",
    "  name_prefix=\"PPO_B03\",\n",
    "  #save_replay_buffer=True,\n",
    "  #save_vecnormalize=True,\n",
    ")\n",
    "eval_callback = EvalCallback(env, n_eval_episodes=3,\n",
    "                             best_model_save_path=os.path.join('Dissertacao','Training_BoxConveyor','Model_saves','PPO_B03_backup','Best_model'),\n",
    "                             log_path=log_path, eval_freq=4096,\n",
    "                             deterministic=False, render=False)\n",
    "callback = CallbackList([checkpoint_callback, ProgressBarCallback(), TensorboardCallback(), eval_callback])\n",
    "print(modelPPO.policy)\n",
    "#model= modelTRPO.load(os.path.join('Dissertacao','Training_BoxConveyor','Model_saves','TRPO1_B75'),env=env,print_system_info=True)#\n",
    "model= modelPPO\n",
    "ws = websocket.WebSocket()\n",
    "\n",
    "ws.connect(\"ws://127.0.0.2:12000\")\n",
    "time.sleep(1)\n",
    "######-----reward estatica\n",
    "for i in range(1):\n",
    "    model.learn(total_timesteps=1000000,log_interval=200,callback=callback) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f3cda8",
   "metadata": {},
   "source": [
    "# Avaliar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c38d0bbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "== CURRENT SYSTEM INFO ==\n",
      "OS: Windows-10-10.0.19044-SP0 10.0.19044\n",
      "Python: 3.9.7\n",
      "Stable-Baselines3: 1.5.1a5\n",
      "PyTorch: 1.13.1\n",
      "GPU Enabled: True\n",
      "Numpy: 1.24.2\n",
      "Gym: 0.21.0\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "OS: Windows-10-10.0.19044-SP0 10.0.19044\n",
      "Python: 3.9.7\n",
      "Stable-Baselines3: 1.5.1a5\n",
      "PyTorch: 1.13.0\n",
      "GPU Enabled: True\n",
      "Numpy: 1.20.3\n",
      "Gym: 0.21.0\n",
      "\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0. 0. 0. 0.]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   0.15]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   0.31]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   0.46]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   1.   0.   0.61]\n",
      "recompensa:  100 |  acao -->  0 |  done:  False | Estado:  [0.   1.   0.   0.62]\n",
      "recompensa:  100 |  acao -->  0 |  done:  False | Estado:  [0.   1.   0.   0.62]\n",
      "recompensa:  100 |  acao -->  0 |  done:  False | Estado:  [1.   1.   0.   0.62]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   1.   0.   0.77]\n",
      "recompensa:  100 |  acao -->  0 |  done:  False | Estado:  [0.   1.   0.   0.77]\n",
      "recompensa:  100 |  acao -->  0 |  done:  False | Estado:  [0.   1.   0.   0.77]\n",
      "recompensa:  100 |  acao -->  0 |  done:  False | Estado:  [1.   1.   0.   0.77]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   1.   0.   0.92]\n",
      "recompensa:  100 |  acao -->  0 |  done:  False | Estado:  [0.   1.   0.   0.93]\n",
      "recompensa:  100 |  acao -->  0 |  done:  False | Estado:  [0.   1.   0.   0.93]\n",
      "recompensa:  100 |  acao -->  0 |  done:  False | Estado:  [1.   1.   0.   0.93]\n",
      "recompensa:  0 |  acao -->  2 |  done:  False | Estado:  [0.   1.   0.   0.73]\n",
      "recompensa:  0 |  acao -->  2 |  done:  False | Estado:  [0.   0.   0.   0.55]\n",
      "recompensa:  0 |  acao -->  2 |  done:  False | Estado:  [0.   0.   0.   0.36]\n",
      "recompensa:  0 |  acao -->  2 |  done:  False | Estado:  [0.   0.   0.   0.17]\n",
      "recompensa:  0 |  acao -->  2 |  done:  False | Estado:  [0. 0. 0. 0.]\n",
      "recompensa:  0 |  acao -->  2 |  done:  False | Estado:  [0. 0. 1. 0.]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0. 0. 1. 0.]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0. 0. 1. 0.]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0. 0. 1. 0.]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0. 0. 1. 0.]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0. 0. 1. 0.]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0. 0. 1. 0.]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0. 0. 1. 0.]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0. 0. 1. 0.]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   1.   0.15]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   0.31]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   0.46]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   0.61]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   0.77]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   0.92]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   1.07]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   1.23]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   1.38]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   1.53]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   1.69]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   1.   1.84]\n",
      "recompensa:  100 |  acao -->  1 |  done:  False | Estado:  [0.   0.   1.   1.94]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   1.   1.99]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   1.   2.15]\n",
      "recompensa:  0 |  acao -->  1 |  done:  True | Estado:  [0.  0.  0.  2.3]\n",
      "recompensa:  0 |  acao -->  1 |  done:  False | Estado:  [0.   0.   0.   2.45]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2120/176796538.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \"\"\"\n\u001b[0;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mVecEnvStepReturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             )\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# del modelTRPO\n",
    "# del model\n",
    "save_path = os.path.join('Dissertacao','Training_BoxConveyor','Model_saves','A2C_B25')\n",
    "policy_kwargs = dict(activation_fn=th.nn.Tanh)\n",
    "#policy_kwargs = dict(activation_fn=th.nn.Tanh,\n",
    "#                     net_arch=[dict(pi=[6,60,30,60,9], vf=[6,60,30,60,9])])\n",
    "env=DrillEnv()\n",
    "env.setprint(True)\n",
    "env=DummyVecEnv([lambda: env])\n",
    "env.reset()\n",
    "\n",
    "modelA2C=A2C('MlpPolicy',env,verbose=1,\n",
    "             #n_steps=5000,\n",
    "             gamma=0.95, gae_lambda=0.90,\n",
    "             seed=9,\n",
    "             policy_kwargs=policy_kwargs)\n",
    "\n",
    "model= modelA2C.load(save_path,env=env,print_system_info=True)\n",
    "#model= modelTRPO\n",
    "ws = websocket.WebSocket()\n",
    "\n",
    "ws.connect(\"ws://127.0.0.1:12000\")\n",
    "time.sleep(1)\n",
    "mensagem = encode_json('CanConveyor_automatico', [])\n",
    "ws.send(mensagem)\n",
    "mensagem = encode_json('Handling_automatico', [])\n",
    "time.sleep(1)\n",
    "ws.send(mensagem)\n",
    "# mensagem = encode_json('BoxConveyor_automatico', [])\n",
    "# time.sleep(1)\n",
    "# ws.send(mensagem)\n",
    "obs = env.reset()\n",
    "while True: \n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done: \n",
    "        obs = env.reset()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5366dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
